{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import logging\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STOPWORDS.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.reuters.com/article/clariant-resul...</td>\n",
       "      <td>Clariant keeps full year guidance after meetin...</td>\n",
       "      <td>ZURICH, July 27 Swiss chemicals group Clariant...</td>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.reuters.com/article/clariant-resul...</td>\n",
       "      <td>Clariant keeps full year guidance after meetin...</td>\n",
       "      <td>ZURICH, July 27 Swiss chemicals group Clariant...</td>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.reuters.com/article/clariant-resul...</td>\n",
       "      <td>Clariant keeps full year guidance after meetin...</td>\n",
       "      <td>ZURICH, July 27 Swiss chemicals group Clariant...</td>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reuters.com/article/clariant-resul...</td>\n",
       "      <td>Clariant keeps full year guidance after meetin...</td>\n",
       "      <td>ZURICH, July 27 Swiss chemicals group Clariant...</td>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.reuters.com/article/clariant-resul...</td>\n",
       "      <td>Clariant keeps full year guidance after meetin...</td>\n",
       "      <td>ZURICH, July 27 Swiss chemicals group Clariant...</td>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.reuters.com/article/clariant-resul...   \n",
       "1  https://www.reuters.com/article/clariant-resul...   \n",
       "2  https://www.reuters.com/article/clariant-resul...   \n",
       "3  https://www.reuters.com/article/clariant-resul...   \n",
       "4  https://www.reuters.com/article/clariant-resul...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Clariant keeps full year guidance after meetin...   \n",
       "1  Clariant keeps full year guidance after meetin...   \n",
       "2  Clariant keeps full year guidance after meetin...   \n",
       "3  Clariant keeps full year guidance after meetin...   \n",
       "4  Clariant keeps full year guidance after meetin...   \n",
       "\n",
       "                                             content      tag  \n",
       "0  ZURICH, July 27 Swiss chemicals group Clariant...  markets  \n",
       "1  ZURICH, July 27 Swiss chemicals group Clariant...  markets  \n",
       "2  ZURICH, July 27 Swiss chemicals group Clariant...  markets  \n",
       "3  ZURICH, July 27 Swiss chemicals group Clariant...  markets  \n",
       "4  ZURICH, July 27 Swiss chemicals group Clariant...  markets  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/sample.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['clariant', 'keeps', 'full', 'year', 'guidance', 'meeting', 'forecasts', 'h1', 'zurich', 'july', '27', 'swiss', 'chemicals', 'group', 'clariant', 'carrying', '20', 'billion', 'merger', 'u', 'peer', 'huntsman', 'reported', 'first', 'half', 'operating', 'profit', 'line', 'expectations', 'thursday', 'confirmed', 'guidance', 'year'], ['clariant', 'keeps', 'full', 'year', 'guidance', 'meeting', 'forecasts', 'h1', 'zurich', 'july', '27', 'swiss', 'chemicals', 'group', 'clariant', 'carrying', '20', 'billion', 'merger', 'u', 'peer', 'huntsman', 'reported', 'first', 'half', 'operating', 'profit', 'line', 'wi', 'guidance', 'year']]\n"
     ]
    }
   ],
   "source": [
    "# remove common words and tokenize\n",
    "data['full_content'] = data['title'] + ' ' + data['content']\n",
    "full_content = data['full_content'].tolist()\n",
    "full_content = [[z for z in tokenizer.tokenize(t.lower()) if z not in STOPWORDS] for t in full_content]\n",
    "print full_content[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['clariant', 'keeps', 'full', 'year', 'guidance', 'meeting', 'forecasts', 'h1', 'zurich', 'july', '27', 'swiss', 'chemicals', 'group', 'clariant', 'carrying', '20', 'billion', 'merger', 'u', 'peer', 'huntsman', 'reported', 'first', 'half', 'operating', 'profit', 'line', 'guidance', 'year'], ['clariant', 'keeps', 'full', 'year', 'guidance', 'meeting', 'forecasts', 'h1', 'zurich', 'july', '27', 'swiss', 'chemicals', 'group', 'clariant', 'carrying', '20', 'billion', 'merger', 'u', 'peer', 'huntsman', 'reported', 'first', 'half', 'operating', 'profit', 'line', 'wi', 'guidance', 'year']]\n"
     ]
    }
   ],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in full_content:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "full_content = [[token for token in text if frequency[token] > 1] for text in full_content]\n",
    "print full_content[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-27 14:03:46,051 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-07-27 14:03:46,067 : INFO : built Dictionary(28 unique tokens: [u'zurich', u'h1', u'year', u'line', u'27']...) from 282 documents (total 8712 corpus positions)\n",
      "2017-07-27 14:03:46,068 : INFO : saving Dictionary object under model/contents.dict, separately None\n",
      "2017-07-27 14:03:46,069 : INFO : saved model/contents.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(28 unique tokens: [u'zurich', u'h1', u'year', u'line', u'27']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(full_content)\n",
    "dictionary.save('model/contents.dict')\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-27 14:03:46,221 : INFO : storing corpus in Matrix Market format to model/contents.mm\n",
      "2017-07-27 14:03:46,222 : INFO : saving sparse matrix to model/contents.mm\n",
      "2017-07-27 14:03:46,222 : INFO : PROGRESS: saving document #0\n",
      "2017-07-27 14:03:46,245 : INFO : saved 282x28 matrix, density=99.658% (7869/7896)\n",
      "2017-07-27 14:03:46,245 : INFO : saving MmCorpus index to model/contents.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in full_content]\n",
    "gensim.corpora.MmCorpus.serialize('model/contents.mm', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config \n",
    "NUM_TOPICS = 10\n",
    "NUM_TERMS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-27 14:03:46,876 : INFO : using symmetric alpha at 0.1\n",
      "2017-07-27 14:03:46,877 : INFO : using symmetric eta at 0.0357142857143\n",
      "2017-07-27 14:03:46,877 : INFO : using serial LDA version on this node\n",
      "2017-07-27 14:03:46,881 : INFO : running online LDA training, 10 topics, 1 passes over the supplied corpus of 282 documents, updating model once every 282 documents, evaluating perplexity every 282 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-07-27 14:03:46,882 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2017-07-27 14:03:47,651 : INFO : -4.120 per-word bound, 17.4 perplexity estimate based on a held-out corpus of 282 documents with 8712 words\n",
      "2017-07-27 14:03:47,651 : INFO : PROGRESS: pass 0, at document #282/282\n",
      "2017-07-27 14:03:48,143 : INFO : topic #3 (0.100): 0.067*\"year\" + 0.063*\"guidance\" + 0.062*\"clariant\" + 0.038*\"zurich\" + 0.038*\"group\" + 0.037*\"meeting\" + 0.036*\"20\" + 0.036*\"wi\" + 0.036*\"forecasts\" + 0.035*\"half\"\n",
      "2017-07-27 14:03:48,144 : INFO : topic #9 (0.100): 0.068*\"guidance\" + 0.050*\"clariant\" + 0.049*\"year\" + 0.041*\"merger\" + 0.040*\"peer\" + 0.040*\"full\" + 0.038*\"half\" + 0.037*\"swiss\" + 0.036*\"operating\" + 0.036*\"first\"\n",
      "2017-07-27 14:03:48,144 : INFO : topic #6 (0.100): 0.068*\"clariant\" + 0.067*\"year\" + 0.063*\"guidance\" + 0.034*\"carrying\" + 0.034*\"chemicals\" + 0.034*\"line\" + 0.034*\"forecasts\" + 0.034*\"keeps\" + 0.034*\"first\" + 0.033*\"wi\"\n",
      "2017-07-27 14:03:48,145 : INFO : topic #7 (0.100): 0.067*\"year\" + 0.063*\"guidance\" + 0.061*\"clariant\" + 0.036*\"operating\" + 0.036*\"huntsman\" + 0.036*\"full\" + 0.035*\"reported\" + 0.035*\"profit\" + 0.034*\"july\" + 0.034*\"keeps\"\n",
      "2017-07-27 14:03:48,146 : INFO : topic #2 (0.100): 0.063*\"year\" + 0.063*\"guidance\" + 0.058*\"clariant\" + 0.040*\"meeting\" + 0.039*\"profit\" + 0.038*\"reported\" + 0.038*\"h1\" + 0.036*\"zurich\" + 0.035*\"billion\" + 0.034*\"chemicals\"\n",
      "2017-07-27 14:03:48,146 : INFO : topic diff=0.856286, rho=1.000000\n",
      "2017-07-27 14:03:48,147 : INFO : saving LdaState object under model/lda.save.state, separately None\n",
      "2017-07-27 14:03:48,147 : INFO : saved model/lda.save.state\n",
      "2017-07-27 14:03:48,148 : INFO : saving LdaModel object under model/lda.save, separately ['expElogbeta', 'sstats']\n",
      "2017-07-27 14:03:48,148 : INFO : not storing attribute id2word\n",
      "2017-07-27 14:03:48,149 : INFO : storing np array 'expElogbeta' to model/lda.save.expElogbeta.npy\n",
      "2017-07-27 14:03:48,150 : INFO : not storing attribute state\n",
      "2017-07-27 14:03:48,150 : INFO : not storing attribute dispatcher\n",
      "2017-07-27 14:03:48,151 : INFO : saved model/lda.save\n"
     ]
    }
   ],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, \n",
    "                                      num_topics=10, update_every=1, \n",
    "                                      chunksize=10000, passes=1)\n",
    "\n",
    "lda.save('model/lda.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-27 14:03:48,155 : INFO : topic #0 (0.100): 0.075*\"guidance\" + 0.057*\"clariant\" + 0.054*\"year\" + 0.041*\"first\" + 0.040*\"peer\" + 0.040*\"carrying\" + 0.039*\"huntsman\" + 0.038*\"swiss\" + 0.037*\"u\" + 0.037*\"keeps\"\n",
      "2017-07-27 14:03:48,155 : INFO : topic #7 (0.100): 0.067*\"year\" + 0.063*\"guidance\" + 0.061*\"clariant\" + 0.036*\"operating\" + 0.036*\"huntsman\" + 0.036*\"full\" + 0.035*\"reported\" + 0.035*\"profit\" + 0.034*\"july\" + 0.034*\"keeps\"\n",
      "2017-07-27 14:03:48,156 : INFO : topic #6 (0.100): 0.068*\"clariant\" + 0.067*\"year\" + 0.063*\"guidance\" + 0.034*\"carrying\" + 0.034*\"chemicals\" + 0.034*\"line\" + 0.034*\"forecasts\" + 0.034*\"keeps\" + 0.034*\"first\" + 0.033*\"wi\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.075*\"guidance\" + 0.057*\"clariant\" + 0.054*\"year\" + 0.041*\"first\" + 0.040*\"peer\" + 0.040*\"carrying\" + 0.039*\"huntsman\" + 0.038*\"swiss\" + 0.037*\"u\" + 0.037*\"keeps\"'),\n",
       " (7,\n",
       "  u'0.067*\"year\" + 0.063*\"guidance\" + 0.061*\"clariant\" + 0.036*\"operating\" + 0.036*\"huntsman\" + 0.036*\"full\" + 0.035*\"reported\" + 0.035*\"profit\" + 0.034*\"july\" + 0.034*\"keeps\"'),\n",
       " (6,\n",
       "  u'0.068*\"clariant\" + 0.067*\"year\" + 0.063*\"guidance\" + 0.034*\"carrying\" + 0.034*\"chemicals\" + 0.034*\"line\" + 0.034*\"forecasts\" + 0.034*\"keeps\" + 0.034*\"first\" + 0.033*\"wi\"')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'guidance', u'clariant', u'year', u'first', u'peer', u'carrying', u'huntsman', u'swiss', u'u', u'keeps', u'full', u'wi', u'20', u'chemicals', u'group', u'meeting', u'27', u'merger', u'billion', u'forecasts', u'operating', u'half', u'reported', u'line', u'zurich', u'h1', u'profit', u'july'], [u'guidance', u'clariant', u'year', u'27', u'operating', u'wi', u'first', u'merger', u'half', u'peer', u'full', u'u', u'keeps', u'huntsman', u'h1', u'july', u'line', u'zurich', u'billion', u'chemicals', u'20', u'swiss', u'meeting', u'forecasts', u'reported', u'profit', u'carrying', u'group'], [u'year', u'guidance', u'clariant', u'meeting', u'profit', u'reported', u'h1', u'zurich', u'billion', u'chemicals', u'july', u'operating', u'huntsman', u'wi', u'27', u'20', u'carrying', u'half', u'group', u'swiss', u'first', u'peer', u'merger', u'line', u'full', u'keeps', u'u', u'forecasts']]\n"
     ]
    }
   ],
   "source": [
    "# select top 100 words for each of the 10 LDA topics\n",
    "TOP_KEYWORDS = [[word for word, _ in lda.show_topic(topicno, topn=NUM_TERMS)]\n",
    "             for topicno in range(lda.num_topics)]\n",
    "print(TOP_KEYWORDS[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to  exported/lda/lda_topic_0.csv\n",
      "Saved to  exported/lda/lda_topic_1.csv\n",
      "Saved to  exported/lda/lda_topic_2.csv\n",
      "Saved to  exported/lda/lda_topic_3.csv\n",
      "Saved to  exported/lda/lda_topic_4.csv\n",
      "Saved to  exported/lda/lda_topic_5.csv\n",
      "Saved to  exported/lda/lda_topic_6.csv\n",
      "Saved to  exported/lda/lda_topic_7.csv\n",
      "Saved to  exported/lda/lda_topic_8.csv\n",
      "Saved to  exported/lda/lda_topic_9.csv\n"
     ]
    }
   ],
   "source": [
    "# Export \n",
    "n = 0\n",
    "for _ in TOP_KEYWORDS:\n",
    "    save_to = \"exported/lda/lda_topic_%s.csv\" % n\n",
    "    pd.DataFrame(_, columns=['keyword']).to_csv(save_to, index=False)\n",
    "    n += 1\n",
    "    print 'Saved to ', save_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 10\n",
    "NUM_TERMS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-27 14:03:48,177 : INFO : collecting document frequencies\n",
      "2017-07-27 14:03:48,178 : INFO : PROGRESS: processing document #0\n",
      "2017-07-27 14:03:48,180 : INFO : calculating IDF weights for 282 documents and 27 features (7869 matrix non-zeros)\n",
      "2017-07-27 14:03:48,181 : INFO : saving TfidfModel object under model/tfidf.save, separately None\n",
      "2017-07-27 14:03:48,182 : INFO : saved model/tfidf.save\n"
     ]
    }
   ],
   "source": [
    "tfidf = gensim.models.tfidfmodel.TfidfModel(corpus, id2word=dictionary)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "tfidf.save(\"model/tfidf.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_sorted = []\n",
    "TOP_KEYWORDS = []\n",
    "for c in corpus_tfidf:\n",
    "    top_keywords = sorted(c, key=lambda t: t[1], reverse=True)\n",
    "    top_keywords = top_keywords[:NUM_TERMS]\n",
    "    corpus_tfidf_sorted.append(top_keywords)\n",
    "    TOP_KEYWORDS.append([dictionary[id] for id, _ in top_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'year', u'guidance', u'zurich', u'h1', u'line', u'27', u'20', u'merger', u'meeting', u'full', u'huntsman', u'forecasts', u'reported', u'chemicals', u'carrying', u'operating', u'half', u'peer', u'group', u'july', u'billion', u'profit', u'u', u'swiss', u'first'], [u'wi', u'year', u'guidance', u'zurich', u'h1', u'line', u'27', u'20', u'merger', u'meeting', u'full', u'huntsman', u'forecasts', u'reported', u'chemicals', u'carrying', u'operating', u'half', u'peer', u'group', u'july', u'billion', u'profit', u'u', u'swiss', u'first']]\n"
     ]
    }
   ],
   "source": [
    "print TOP_KEYWORDS[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total keywords:  7305\n",
      "Total keywords after combined:  26\n",
      "[u'zurich', u'h1', u'year', u'line', u'27', u'20', u'merger', u'guidance', u'meeting', u'full']\n"
     ]
    }
   ],
   "source": [
    "# Combine top keywords\n",
    "import itertools\n",
    "TOP_KEYWORDS_MERGED = list(itertools.chain(*TOP_KEYWORDS))\n",
    "print \"Total keywords: \", len(TOP_KEYWORDS_MERGED)\n",
    "TOP_KEYWORDS_MERGED = list(set(TOP_KEYWORDS_MERGED))\n",
    "print \"Total keywords after combined: \", len(TOP_KEYWORDS_MERGED)\n",
    "print TOP_KEYWORDS_MERGED[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to  exported/tfidf/tfidf_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "# Export \n",
    "save_to = \"exported/tfidf/tfidf_keywords.csv\"\n",
    "pd.DataFrame(TOP_KEYWORDS_MERGED, columns=['keyword']).to_csv(save_to, index=False)\n",
    "print 'Saved to ', save_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF with K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 10\n",
    "NUM_TERMS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(corpus_tfidf).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-ba725acc3296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLUSTERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    878\u001b[0m         \"\"\"\n\u001b[1;32m    879\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.pyc\u001b[0m in \u001b[0;36m_check_fit_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;34m\"\"\"Verify that the number of samples given is larger than k\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             raise ValueError(\"n_samples=%d should be >= n_clusters=%d\" % (\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
