{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STOPWORDS.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/new_brand_reuter.csv  =>  645 rows\n",
      "Unique row: 644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>time</th>\n",
       "      <th>short_text</th>\n",
       "      <th>long_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.reuters.com/article/press-digest-n...</td>\n",
       "      <td>PRESS DIGEST- New York Times business news - J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>June 22, 2017 /  5:19 AM / a month ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>June 22 (Reuters) - The following are the top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.reuters.com/article/us-peugeot-ira...</td>\n",
       "      <td>PSA wins second Iran production deal for Citro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July 21, 2016 /  3:36 PM / a year ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PARIS (Reuters) - PSA Group unveiled a second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.reuters.com/article/peugeot-iran-i...</td>\n",
       "      <td>PSA wins second Iran production deal for Citro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July 21, 2016 /  3:36 PM / a year ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PARIS (Reuters) - PSA Group unveiled a second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reuters.com/article/idUSFWN18K07G</td>\n",
       "      <td>BRIEF-Abercrombie &amp; Fitch appoints new brand p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May 23, 2016 /  12:25 PM / a year ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May 23 (Reuters) - Abercrombie &amp; Fitch Co : * ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.reuters.com/article/press-digest-n...</td>\n",
       "      <td>PRESS DIGEST- New York Times business news - J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July 24, 2017 /  5:37 AM / 4 days ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July 24 (Reuters) - The following are the top ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.reuters.com/article/press-digest-n...   \n",
       "1  https://www.reuters.com/article/us-peugeot-ira...   \n",
       "2  https://www.reuters.com/article/peugeot-iran-i...   \n",
       "3      https://www.reuters.com/article/idUSFWN18K07G   \n",
       "4  https://www.reuters.com/article/press-digest-n...   \n",
       "\n",
       "                                               title  tag  \\\n",
       "0  PRESS DIGEST- New York Times business news - J...  NaN   \n",
       "1  PSA wins second Iran production deal for Citro...  NaN   \n",
       "2  PSA wins second Iran production deal for Citro...  NaN   \n",
       "3  BRIEF-Abercrombie & Fitch appoints new brand p...  NaN   \n",
       "4  PRESS DIGEST- New York Times business news - J...  NaN   \n",
       "\n",
       "                                     time short_text  \\\n",
       "0  June 22, 2017 /  5:19 AM / a month ago        NaN   \n",
       "1   July 21, 2016 /  3:36 PM / a year ago        NaN   \n",
       "2   July 21, 2016 /  3:36 PM / a year ago        NaN   \n",
       "3   May 23, 2016 /  12:25 PM / a year ago        NaN   \n",
       "4   July 24, 2017 /  5:37 AM / 4 days ago        NaN   \n",
       "\n",
       "                                           long_text  \n",
       "0  June 22 (Reuters) - The following are the top ...  \n",
       "1  PARIS (Reuters) - PSA Group unveiled a second ...  \n",
       "2  PARIS (Reuters) - PSA Group unveiled a second ...  \n",
       "3  May 23 (Reuters) - Abercrombie & Fitch Co : * ...  \n",
       "4  July 24 (Reuters) - The following are the top ...  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# close_branch_reuter, deal_reuter, layoff_reuter, m_a_reuter, new_branch_reuter, new_brand_reuter\n",
    "KEYWORD_TYPE = 'new_brand_reuter'\n",
    "\n",
    "# Input file\n",
    "INPUT_FILE = \"data/\"+ KEYWORD_TYPE +\".csv\"\n",
    "\n",
    "data = pd.read_csv(INPUT_FILE, encoding='utf-8', dtype={'short_text': str, 'long_text': str})\n",
    "print 'Reading', INPUT_FILE, ' => ' , len(data.index), 'rows'\n",
    "data.drop_duplicates(inplace=True)\n",
    "# data['short_text'] = data.short_text.astype(str)\n",
    "print \"Unique row:\", len(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allFiles = glob.glob(\"data/*.csv\")\n",
    "# data = pd.DataFrame()\n",
    "# list_ = []\n",
    "# for file_ in allFiles:\n",
    "#     df = pd.read_csv(file_, dtype={'short_text': str, 'long_text': str})\n",
    "#     list_.append(df)\n",
    "# data = pd.concat(list_)\n",
    "\n",
    "# data.drop_duplicates(inplace=True)\n",
    "# print \"Unique row:\", len(data)\n",
    "# data.head()\n",
    "\n",
    "# data.to_csv(\"concat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'press', u'digest', u'new', u'york', u'time', u'business', u'news', u'june', u'22', u'june', u'22', u'reuters', u'following', u'top', u'story', u'new', u'york', u'time', u'business', u'page', u'reuters', u'verified', u'story', u'vouch', u'accuracy', u'travis', u'kalanick', u'stepped', u'chief', u'executive', u'uber', u'technology', u'inc', u'ride', u'hailing', u'service', u'helped', u'found', u'2009', u'built', u'transportation', u'colossus', u'shareholder', u'revolt', u'made', u'untenable', u'stay', u'company', u'nyti', u'm', u'2st1oh6', u'magazine', u'publisher', u'wenner', u'medium', u'agreed', u'sell', u'men', u'lifestyle', u'title', u'american', u'medium', u'focus', u'expanding', u'remaining', u'brand', u'rolling', u'stone', u'nyti', u'm', u'2st1ijl', u'appeal', u'court', u'set', u'rule', u'whether', u'premium', u'subscriber', u'based', u'news', u'organization', u'protection', u'traditional', u'medium', u'company', u'nyti', u'm', u'2st2vk4', u'compiled', u'bengaluru', u'newsroom'], [u'psa', u'win', u'second', u'iran', u'production', u'deal', u'citroen', u'brand', u'paris', u'reuters', u'psa', u'group', u'unveiled', u'second', u'iranian', u'manufacturing', u'deal', u'thursday', u'french', u'carmaker', u'seek', u'reclaim', u'leading', u'position', u'enjoyed', u'middle', u'east', u'biggest', u'auto', u'market', u'u', u'led', u'sanction', u'forced', u'withdrawal', u'paris', u'based', u'carmaker', u'struck', u'framework', u'deal', u'iranian', u'counterpart', u'saipa', u'invest', u'300', u'million', u'euro', u'330', u'million', u'development', u'production', u'three', u'citroen', u'model', u'new', u'joint', u'venture', u'psa', u'pulled', u'2011', u'u', u'pressure', u'face', u'stiffer', u'competition', u'chinese', u'rival', u'grabbed', u'business', u'intervening', u'year', u'well', u'western', u'peer', u'renault', u'flocking', u'back', u'newer', u'model', u'agreement', u'open', u'new', u'chapter', u'history', u'cooperation', u'saipa', u'psa', u'chief', u'executive', u'carlos', u'tavares', u'said', u'aim', u'provide', u'iranian', u'customer', u'modern', u'vehicle', u'meet', u'highest', u'comfort', u'safety', u'technology', u'standard', u'iranian', u'car', u'registration', u'approached', u'1', u'6', u'million', u'car', u'2011', u'peak', u'psa', u'claiming', u'almost', u'30', u'percent', u'market', u'collapsing', u'weight', u'sanction', u'deal', u'saipa', u'citroen', u'partner', u'since', u'1966', u'follows', u'joint', u'venture', u'deal', u'inked', u'last', u'month', u'stablemate', u'peugeot', u'state', u'owned', u'iran', u'khodro', u'psa', u'smaller', u'd', u'premium', u'badge', u'also', u'clinched', u'distribution', u'agreement', u'country', u'agreement', u'finalised', u'end', u'2016', u'citroen', u'iranian', u'partner', u'introduce', u'first', u'three', u'planned', u'new', u'model', u'french', u'brand', u'2018', u'reporting', u'laurence', u'frost', u'editing', u'jane', u'merriman', u'alexandra', u'hudson']]\n"
     ]
    }
   ],
   "source": [
    "# remove common words and tokenize\n",
    "data['full_content'] = data['title'] + ' ' + data['long_text']\n",
    "full_content = data['full_content'].tolist()\n",
    "# full_content = [[wordnet_lemmatizer.lemmatize(z) for z in tokenizer.tokenize(str(t).decode('utf-8').lower()) if z not in STOPWORDS] for t in full_content]\n",
    "# full_content = [[z for z in str(t).lower().split(\" \") if z not in STOPWORDS] for t in full_content]\n",
    "full_content = [[wordnet_lemmatizer.lemmatize(z) for z in tokenizer.tokenize(unicode(t).lower()) if z not in STOPWORDS] for t in full_content]\n",
    "print full_content[:2]\n",
    "with open(\"full_content\", \"wb\") as f:\n",
    "    f.write(str(full_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'press', u'digest', u'new', u'york', u'time', u'business', u'news', u'june', u'june', u'reuters', u'following', u'top', u'story', u'new', u'york', u'time', u'business', u'page', u'reuters', u'verified', u'story', u'vouch', u'accuracy', u'travis', u'kalanick', u'stepped', u'chief', u'executive', u'uber', u'technology', u'inc', u'ride', u'hailing', u'service', u'helped', u'found', u'built', u'transportation', u'shareholder', u'revolt', u'made', u'stay', u'company', u'nyti', u'm', u'magazine', u'publisher', u'medium', u'agreed', u'sell', u'men', u'lifestyle', u'title', u'american', u'medium', u'focus', u'expanding', u'remaining', u'brand', u'rolling', u'stone', u'nyti', u'm', u'appeal', u'court', u'set', u'rule', u'whether', u'premium', u'subscriber', u'based', u'news', u'organization', u'protection', u'traditional', u'medium', u'company', u'nyti', u'm', u'compiled', u'bengaluru', u'newsroom'], [u'psa', u'win', u'second', u'iran', u'production', u'deal', u'citroen', u'brand', u'paris', u'reuters', u'psa', u'group', u'unveiled', u'second', u'iranian', u'manufacturing', u'deal', u'thursday', u'french', u'carmaker', u'seek', u'reclaim', u'leading', u'position', u'enjoyed', u'middle', u'east', u'biggest', u'auto', u'market', u'u', u'led', u'sanction', u'forced', u'withdrawal', u'paris', u'based', u'carmaker', u'struck', u'framework', u'deal', u'iranian', u'counterpart', u'saipa', u'invest', u'million', u'euro', u'million', u'development', u'production', u'three', u'citroen', u'model', u'new', u'joint', u'venture', u'psa', u'pulled', u'u', u'pressure', u'face', u'stiffer', u'competition', u'chinese', u'rival', u'grabbed', u'business', u'intervening', u'year', u'well', u'western', u'peer', u'renault', u'flocking', u'back', u'newer', u'model', u'agreement', u'open', u'new', u'chapter', u'history', u'cooperation', u'saipa', u'psa', u'chief', u'executive', u'carlos', u'tavares', u'said', u'aim', u'provide', u'iranian', u'customer', u'modern', u'vehicle', u'meet', u'highest', u'comfort', u'safety', u'technology', u'standard', u'iranian', u'car', u'registration', u'approached', u'million', u'car', u'peak', u'psa', u'claiming', u'almost', u'percent', u'market', u'collapsing', u'weight', u'sanction', u'deal', u'saipa', u'citroen', u'partner', u'since', u'follows', u'joint', u'venture', u'deal', u'inked', u'last', u'month', u'stablemate', u'peugeot', u'state', u'owned', u'iran', u'khodro', u'psa', u'smaller', u'd', u'premium', u'badge', u'also', u'clinched', u'distribution', u'agreement', u'country', u'agreement', u'finalised', u'end', u'citroen', u'iranian', u'partner', u'introduce', u'first', u'three', u'planned', u'new', u'model', u'french', u'brand', u'reporting', u'laurence', u'frost', u'editing', u'jane', u'merriman', u'alexandra', u'hudson']]\n"
     ]
    }
   ],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in full_content:\n",
    "    for token in text:\n",
    "        if not token.isdigit():\n",
    "            frequency[token] += 1\n",
    "\n",
    "full_content = [[token for token in text if frequency[token] > 1] for text in full_content]\n",
    "print full_content[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-29 10:48:47,513 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-07-29 10:48:47,664 : INFO : built Dictionary(9193 unique tokens: [u'nordisk', u'sinjar', u'yellow', u'four', u'yimin']...) from 644 documents (total 148608 corpus positions)\n",
      "2017-07-29 10:48:47,665 : INFO : saving Dictionary object under model/contents.dict, separately None\n",
      "2017-07-29 10:48:47,683 : INFO : saved model/contents.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(9193 unique tokens: [u'nordisk', u'sinjar', u'yellow', u'four', u'yimin']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(full_content)\n",
    "dictionary.save('model/contents.dict')\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-29 10:48:47,816 : INFO : storing corpus in Matrix Market format to model/contents.mm\n",
      "2017-07-29 10:48:47,817 : INFO : saving sparse matrix to model/contents.mm\n",
      "2017-07-29 10:48:47,818 : INFO : PROGRESS: saving document #0\n",
      "2017-07-29 10:48:48,081 : INFO : saved 644x9193 matrix, density=1.609% (95253/5920292)\n",
      "2017-07-29 10:48:48,082 : INFO : saving MmCorpus index to model/contents.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in full_content]\n",
    "gensim.corpora.MmCorpus.serialize('model/contents.mm', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config \n",
    "NUM_TOPICS = 5\n",
    "NUM_TERMS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-29 10:48:48,092 : INFO : using symmetric alpha at 0.2\n",
      "2017-07-29 10:48:48,093 : INFO : using symmetric eta at 0.000108778418362\n",
      "2017-07-29 10:48:48,096 : INFO : using serial LDA version on this node\n",
      "2017-07-29 10:48:48,525 : INFO : running online LDA training, 5 topics, 1 passes over the supplied corpus of 644 documents, updating model once every 644 documents, evaluating perplexity every 644 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-07-29 10:48:48,526 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2017-07-29 10:48:52,417 : INFO : -9.847 per-word bound, 921.0 perplexity estimate based on a held-out corpus of 644 documents with 148608 words\n",
      "2017-07-29 10:48:52,417 : INFO : PROGRESS: pass 0, at document #644/644\n",
      "2017-07-29 10:48:53,567 : INFO : topic #0 (0.200): 0.017*\"said\" + 0.013*\"brand\" + 0.009*\"new\" + 0.007*\"year\" + 0.006*\"company\" + 0.006*\"china\" + 0.005*\"reuters\" + 0.005*\"sale\" + 0.005*\"group\" + 0.004*\"percent\"\n",
      "2017-07-29 10:48:53,568 : INFO : topic #1 (0.200): 0.012*\"new\" + 0.012*\"brand\" + 0.009*\"said\" + 0.008*\"company\" + 0.006*\"year\" + 0.006*\"reuters\" + 0.006*\"percent\" + 0.005*\"u\" + 0.005*\"market\" + 0.005*\"rating\"\n",
      "2017-07-29 10:48:53,568 : INFO : topic #2 (0.200): 0.016*\"new\" + 0.013*\"said\" + 0.009*\"year\" + 0.008*\"company\" + 0.007*\"brand\" + 0.006*\"reuters\" + 0.004*\"also\" + 0.004*\"percent\" + 0.004*\"business\" + 0.004*\"trump\"\n",
      "2017-07-29 10:48:53,569 : INFO : topic #3 (0.200): 0.012*\"said\" + 0.011*\"new\" + 0.009*\"company\" + 0.008*\"brand\" + 0.006*\"year\" + 0.004*\"sale\" + 0.004*\"percent\" + 0.004*\"rating\" + 0.004*\"reuters\" + 0.004*\"market\"\n",
      "2017-07-29 10:48:53,570 : INFO : topic #4 (0.200): 0.020*\"brand\" + 0.015*\"said\" + 0.009*\"new\" + 0.009*\"sale\" + 0.009*\"year\" + 0.008*\"percent\" + 0.007*\"company\" + 0.007*\"reuters\" + 0.006*\"u\" + 0.005*\"market\"\n",
      "2017-07-29 10:48:53,571 : INFO : topic diff=1.624590, rho=1.000000\n",
      "2017-07-29 10:48:53,573 : INFO : saving LdaState object under model/lda.save.state, separately None\n",
      "2017-07-29 10:48:53,574 : INFO : saved model/lda.save.state\n",
      "2017-07-29 10:48:53,595 : INFO : saving LdaModel object under model/lda.save, separately ['expElogbeta', 'sstats']\n",
      "2017-07-29 10:48:53,595 : INFO : not storing attribute id2word\n",
      "2017-07-29 10:48:53,596 : INFO : storing np array 'expElogbeta' to model/lda.save.expElogbeta.npy\n",
      "2017-07-29 10:48:53,597 : INFO : not storing attribute state\n",
      "2017-07-29 10:48:53,597 : INFO : not storing attribute dispatcher\n",
      "2017-07-29 10:48:53,598 : INFO : saved model/lda.save\n"
     ]
    }
   ],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, \n",
    "                                      num_topics=NUM_TOPICS, update_every=1, \n",
    "                                      chunksize=10000, passes=1)\n",
    "\n",
    "lda.save('model/lda.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-29 10:48:53,603 : INFO : topic #4 (0.200): 0.020*\"brand\" + 0.015*\"said\" + 0.009*\"new\" + 0.009*\"sale\" + 0.009*\"year\" + 0.008*\"percent\" + 0.007*\"company\" + 0.007*\"reuters\" + 0.006*\"u\" + 0.005*\"market\" + 0.004*\"group\" + 0.004*\"business\" + 0.004*\"car\" + 0.004*\"million\" + 0.004*\"also\" + 0.004*\"source\" + 0.003*\"china\" + 0.003*\"vw\" + 0.003*\"editing\" + 0.003*\"reporting\" + 0.003*\"fitch\" + 0.003*\"would\" + 0.003*\"share\" + 0.003*\"inc\" + 0.003*\"vehicle\" + 0.003*\"say\" + 0.002*\"rating\" + 0.002*\"plan\" + 0.002*\"last\" + 0.002*\"billion\" + 0.002*\"state\" + 0.002*\"chief\" + 0.002*\"model\" + 0.002*\"one\" + 0.002*\"month\" + 0.002*\"trump\" + 0.002*\"co\" + 0.002*\"motor\" + 0.002*\"executive\" + 0.002*\"volkswagen\" + 0.002*\"next\" + 0.002*\"including\" + 0.002*\"electric\" + 0.002*\"growth\" + 0.002*\"deal\" + 0.002*\"first\" + 0.002*\"coverage\" + 0.002*\"product\" + 0.002*\"may\" + 0.002*\"report\" + 0.002*\"could\" + 0.002*\"profit\" + 0.002*\"united\" + 0.002*\"news\" + 0.002*\"time\" + 0.002*\"euro\" + 0.002*\"price\" + 0.002*\"suv\" + 0.002*\"right\" + 0.002*\"store\" + 0.002*\"consumer\" + 0.002*\"brief\" + 0.002*\"drug\" + 0.002*\"south\" + 0.002*\"analyst\" + 0.002*\"like\" + 0.002*\"end\" + 0.001*\"text\" + 0.001*\"financial\" + 0.001*\"part\" + 0.001*\"audi\" + 0.001*\"two\" + 0.001*\"rival\" + 0.001*\"top\" + 0.001*\"firm\" + 0.001*\"york\" + 0.001*\"told\" + 0.001*\"international\" + 0.001*\"expected\" + 0.001*\"well\" + 0.001*\"march\" + 0.001*\"global\" + 0.001*\"since\" + 0.001*\"investor\" + 0.001*\"biggest\" + 0.001*\"luxury\" + 0.001*\"three\" + 0.001*\"cost\" + 0.001*\"london\" + 0.001*\"ltd\" + 0.001*\"chinese\" + 0.001*\"take\" + 0.001*\"make\" + 0.001*\"industry\" + 0.001*\"president\" + 0.001*\"sell\" + 0.001*\"tuesday\" + 0.001*\"hyundai\" + 0.001*\"n\" + 0.001*\"eikon\"\n",
      "2017-07-29 10:48:53,605 : INFO : topic #2 (0.200): 0.016*\"new\" + 0.013*\"said\" + 0.009*\"year\" + 0.008*\"company\" + 0.007*\"brand\" + 0.006*\"reuters\" + 0.004*\"also\" + 0.004*\"percent\" + 0.004*\"business\" + 0.004*\"trump\" + 0.004*\"group\" + 0.004*\"market\" + 0.004*\"car\" + 0.004*\"u\" + 0.004*\"china\" + 0.004*\"reporting\" + 0.003*\"state\" + 0.003*\"editing\" + 0.003*\"sale\" + 0.003*\"last\" + 0.002*\"million\" + 0.002*\"product\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"one\" + 0.002*\"chief\" + 0.002*\"model\" + 0.002*\"first\" + 0.002*\"including\" + 0.002*\"executive\" + 0.002*\"inc\" + 0.002*\"month\" + 0.002*\"global\" + 0.002*\"co\" + 0.002*\"time\" + 0.002*\"make\" + 0.002*\"world\" + 0.002*\"president\" + 0.002*\"say\" + 0.002*\"week\" + 0.002*\"firm\" + 0.002*\"billion\" + 0.002*\"may\" + 0.002*\"tuesday\" + 0.002*\"fashion\" + 0.002*\"next\" + 0.002*\"government\" + 0.002*\"chinese\" + 0.002*\"united\" + 0.002*\"deal\" + 0.002*\"industry\" + 0.002*\"expected\" + 0.002*\"launch\" + 0.002*\"share\" + 0.002*\"international\" + 0.002*\"growth\" + 0.002*\"vehicle\" + 0.001*\"statement\" + 0.001*\"told\" + 0.001*\"analyst\" + 0.001*\"consumer\" + 0.001*\"according\" + 0.001*\"britain\" + 0.001*\"plan\" + 0.001*\"store\" + 0.001*\"since\" + 0.001*\"york\" + 0.001*\"part\" + 0.001*\"country\" + 0.001*\"news\" + 0.001*\"two\" + 0.001*\"rating\" + 0.001*\"worker\" + 0.001*\"service\" + 0.001*\"people\" + 0.001*\"three\" + 0.001*\"city\" + 0.001*\"name\" + 0.001*\"luxury\" + 0.001*\"financial\" + 0.001*\"sell\" + 0.001*\"change\" + 0.001*\"top\" + 0.001*\"source\" + 0.001*\"based\" + 0.001*\"hotel\" + 0.001*\"right\" + 0.001*\"around\" + 0.001*\"long\" + 0.001*\"high\" + 0.001*\"production\" + 0.001*\"report\" + 0.001*\"retailer\" + 0.001*\"profit\" + 0.001*\"battery\" + 0.001*\"factory\" + 0.001*\"rule\" + 0.001*\"per\" + 0.001*\"phone\" + 0.001*\"show\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4,\n",
       "  u'0.020*\"brand\" + 0.015*\"said\" + 0.009*\"new\" + 0.009*\"sale\" + 0.009*\"year\" + 0.008*\"percent\" + 0.007*\"company\" + 0.007*\"reuters\" + 0.006*\"u\" + 0.005*\"market\" + 0.004*\"group\" + 0.004*\"business\" + 0.004*\"car\" + 0.004*\"million\" + 0.004*\"also\" + 0.004*\"source\" + 0.003*\"china\" + 0.003*\"vw\" + 0.003*\"editing\" + 0.003*\"reporting\" + 0.003*\"fitch\" + 0.003*\"would\" + 0.003*\"share\" + 0.003*\"inc\" + 0.003*\"vehicle\" + 0.003*\"say\" + 0.002*\"rating\" + 0.002*\"plan\" + 0.002*\"last\" + 0.002*\"billion\" + 0.002*\"state\" + 0.002*\"chief\" + 0.002*\"model\" + 0.002*\"one\" + 0.002*\"month\" + 0.002*\"trump\" + 0.002*\"co\" + 0.002*\"motor\" + 0.002*\"executive\" + 0.002*\"volkswagen\" + 0.002*\"next\" + 0.002*\"including\" + 0.002*\"electric\" + 0.002*\"growth\" + 0.002*\"deal\" + 0.002*\"first\" + 0.002*\"coverage\" + 0.002*\"product\" + 0.002*\"may\" + 0.002*\"report\" + 0.002*\"could\" + 0.002*\"profit\" + 0.002*\"united\" + 0.002*\"news\" + 0.002*\"time\" + 0.002*\"euro\" + 0.002*\"price\" + 0.002*\"suv\" + 0.002*\"right\" + 0.002*\"store\" + 0.002*\"consumer\" + 0.002*\"brief\" + 0.002*\"drug\" + 0.002*\"south\" + 0.002*\"analyst\" + 0.002*\"like\" + 0.002*\"end\" + 0.001*\"text\" + 0.001*\"financial\" + 0.001*\"part\" + 0.001*\"audi\" + 0.001*\"two\" + 0.001*\"rival\" + 0.001*\"top\" + 0.001*\"firm\" + 0.001*\"york\" + 0.001*\"told\" + 0.001*\"international\" + 0.001*\"expected\" + 0.001*\"well\" + 0.001*\"march\" + 0.001*\"global\" + 0.001*\"since\" + 0.001*\"investor\" + 0.001*\"biggest\" + 0.001*\"luxury\" + 0.001*\"three\" + 0.001*\"cost\" + 0.001*\"london\" + 0.001*\"ltd\" + 0.001*\"chinese\" + 0.001*\"take\" + 0.001*\"make\" + 0.001*\"industry\" + 0.001*\"president\" + 0.001*\"sell\" + 0.001*\"tuesday\" + 0.001*\"hyundai\" + 0.001*\"n\" + 0.001*\"eikon\"'),\n",
       " (2,\n",
       "  u'0.016*\"new\" + 0.013*\"said\" + 0.009*\"year\" + 0.008*\"company\" + 0.007*\"brand\" + 0.006*\"reuters\" + 0.004*\"also\" + 0.004*\"percent\" + 0.004*\"business\" + 0.004*\"trump\" + 0.004*\"group\" + 0.004*\"market\" + 0.004*\"car\" + 0.004*\"u\" + 0.004*\"china\" + 0.004*\"reporting\" + 0.003*\"state\" + 0.003*\"editing\" + 0.003*\"sale\" + 0.003*\"last\" + 0.002*\"million\" + 0.002*\"product\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"one\" + 0.002*\"chief\" + 0.002*\"model\" + 0.002*\"first\" + 0.002*\"including\" + 0.002*\"executive\" + 0.002*\"inc\" + 0.002*\"month\" + 0.002*\"global\" + 0.002*\"co\" + 0.002*\"time\" + 0.002*\"make\" + 0.002*\"world\" + 0.002*\"president\" + 0.002*\"say\" + 0.002*\"week\" + 0.002*\"firm\" + 0.002*\"billion\" + 0.002*\"may\" + 0.002*\"tuesday\" + 0.002*\"fashion\" + 0.002*\"next\" + 0.002*\"government\" + 0.002*\"chinese\" + 0.002*\"united\" + 0.002*\"deal\" + 0.002*\"industry\" + 0.002*\"expected\" + 0.002*\"launch\" + 0.002*\"share\" + 0.002*\"international\" + 0.002*\"growth\" + 0.002*\"vehicle\" + 0.001*\"statement\" + 0.001*\"told\" + 0.001*\"analyst\" + 0.001*\"consumer\" + 0.001*\"according\" + 0.001*\"britain\" + 0.001*\"plan\" + 0.001*\"store\" + 0.001*\"since\" + 0.001*\"york\" + 0.001*\"part\" + 0.001*\"country\" + 0.001*\"news\" + 0.001*\"two\" + 0.001*\"rating\" + 0.001*\"worker\" + 0.001*\"service\" + 0.001*\"people\" + 0.001*\"three\" + 0.001*\"city\" + 0.001*\"name\" + 0.001*\"luxury\" + 0.001*\"financial\" + 0.001*\"sell\" + 0.001*\"change\" + 0.001*\"top\" + 0.001*\"source\" + 0.001*\"based\" + 0.001*\"hotel\" + 0.001*\"right\" + 0.001*\"around\" + 0.001*\"long\" + 0.001*\"high\" + 0.001*\"production\" + 0.001*\"report\" + 0.001*\"retailer\" + 0.001*\"profit\" + 0.001*\"battery\" + 0.001*\"factory\" + 0.001*\"rule\" + 0.001*\"per\" + 0.001*\"phone\" + 0.001*\"show\"')]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'said', u'brand', u'new', u'year', u'company', u'china', u'reuters', u'sale', u'group', u'percent', u'million', u'car', u'business', u'market', u'would', u'inc', u'also', u'first', u'editing', u'chief', u'yum', u'chinese', u'u', u'say', u'reporting', u'source', u'trump', u'executive', u'analyst', u'world', u'model', u'time', u'last', u'store', u'month', u'people', u'one', u'vehicle', u'vw', u'share', u'cost', u'billion', u'profit', u'week', u'phone', u'electric', u'product', u'make', u'told', u'may', u'global', u'york', u'euro', u'could', u'including', u'president', u'audi', u'quarter', u'luxury', u'plan', u'deal', u'growth', u'fashion', u'state', u'two', u'top', u'since', u'nokia', u'volvo', u'customer', u'news', u'firm', u'division', u'launch', u'expected', u'samsung', u'geely', u'corp', u'ceo', u'country', u'co', u'europe', u'rival', u'comment', u'help', u'around', u'wednesday', u'part', u'long', u'united', u'london', u'local', u'volkswagen', u'operating', u'high', u'industry', u'made', u'emission', u'statement', u'report'], [u'new', u'brand', u'said', u'company', u'year', u'reuters', u'percent', u'u', u'market', u'rating', u'billion', u'million', u'china', u'fitch', u'share', u'business', u'group', u'first', u'would', u'inc', u'york', u'sale', u'also', u'report', u'reporting', u'security', u'fashion', u'time', u'last', u'analyst', u'quarter', u'yum', u'editing', u'state', u'executive', u'store', u'profit', u'financial', u'one', u'chief', u'according', u'growth', u'director', u'product', u'world', u'week', u'president', u'plan', u'per', u'news', u'cost', u'could', u'like', u'car', u'model', u'service', u'say', u'right', u'source', u'country', u'party', u'revenue', u'firm', u'third', u'show', u'based', u'euro', u'told', u'price', u'month', u'term', u'make', u'trump', u'dunkin', u'co', u'may', u'investment', u'global', u'information', u'expected', u'including', u'deal', u'ltd', u'additional', u'take', u'consumer', u'people', u'result', u'vw', u'due', u'tuesday', u'sport', u'rose', u'end', u'credit', u'word', u'issuer', u'following', u'part', u'two'], [u'new', u'said', u'year', u'company', u'brand', u'reuters', u'also', u'percent', u'business', u'trump', u'group', u'market', u'car', u'u', u'china', u'reporting', u'state', u'editing', u'sale', u'last', u'million', u'product', u'would', u'could', u'one', u'chief', u'model', u'first', u'including', u'executive', u'inc', u'month', u'global', u'co', u'time', u'make', u'world', u'president', u'say', u'week', u'firm', u'billion', u'may', u'tuesday', u'fashion', u'next', u'government', u'chinese', u'united', u'deal', u'industry', u'expected', u'launch', u'share', u'international', u'growth', u'vehicle', u'statement', u'told', u'analyst', u'consumer', u'according', u'britain', u'plan', u'store', u'since', u'york', u'part', u'country', u'news', u'two', u'rating', u'worker', u'service', u'people', u'three', u'city', u'name', u'luxury', u'financial', u'sell', u'change', u'top', u'source', u'based', u'hotel', u'right', u'around', u'long', u'high', u'production', u'report', u'retailer', u'profit', u'battery', u'factory', u'rule', u'per', u'phone', u'show']]\n"
     ]
    }
   ],
   "source": [
    "# select top 100 words for each of the 10 LDA topics\n",
    "TOP_KEYWORDS = [[word for word, _ in lda.show_topic(topicno, topn=NUM_TERMS)]\n",
    "             for topicno in range(lda.num_topics)]\n",
    "print(TOP_KEYWORDS[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to  exported/new_brand_reuter.csv\n"
     ]
    }
   ],
   "source": [
    "# Export \n",
    "n = 0\n",
    "combined = []\n",
    "for _ in TOP_KEYWORDS:\n",
    "    combined += _\n",
    "\n",
    "combined_df = pd.DataFrame(combined)\n",
    "combined_df = pd.DataFrame(combined_df[0].value_counts().sort_values()).reset_index()\n",
    "combined_df.columns = ['keyword', 'c']\n",
    "\n",
    "save_to = \"exported/%s.csv\" % KEYWORD_TYPE\n",
    "combined_df[['keyword']].to_csv(save_to, index=False)\n",
    "print 'Saved to ', save_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-240-da59c82888d2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-240-da59c82888d2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "# Break the notebook \n",
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 10\n",
    "NUM_TERMS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = gensim.models.tfidfmodel.TfidfModel(corpus, id2word=dictionary)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "tfidf.save(\"model/tfidf.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_tfidf_sorted = []\n",
    "TOP_KEYWORDS = []\n",
    "for c in corpus_tfidf:\n",
    "    top_keywords = sorted(c, key=lambda t: t[1], reverse=True)\n",
    "    top_keywords = top_keywords[:NUM_TERMS]\n",
    "    corpus_tfidf_sorted.append(top_keywords)\n",
    "    TOP_KEYWORDS.append([dictionary[id] for id, _ in top_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print TOP_KEYWORDS[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine top keywords\n",
    "import itertools\n",
    "TOP_KEYWORDS_MERGED = list(itertools.chain(*TOP_KEYWORDS))\n",
    "print \"Total keywords: \", len(TOP_KEYWORDS_MERGED)\n",
    "TOP_KEYWORDS_MERGED = list(set(TOP_KEYWORDS_MERGED))\n",
    "print \"Total keywords after combined: \", len(TOP_KEYWORDS_MERGED)\n",
    "print TOP_KEYWORDS_MERGED[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export \n",
    "save_to = \"exported/tfidf/tfidf_keywords.csv\"\n",
    "pd.DataFrame(TOP_KEYWORDS_MERGED, columns=['keyword']).to_csv(save_to, index=False, encoding='utf-8')\n",
    "print 'Saved to ', save_to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
